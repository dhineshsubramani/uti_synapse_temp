{
	"name": "WOCDC_FullLoad",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "b829e7ab-9d44-470d-81cb-888f8f1ed670"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql import Row\n",
					"from pyspark.sql import *\n",
					"from pyspark.sql.functions import *\n",
					"from pyspark.sql.types import *\n",
					"from pyspark.sql import functions as F\n",
					"from pyspark.sql import Window\n",
					"from datetime import datetime"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.functions import *\n",
					"from pyspark.sql import Window\n",
					" \n",
					"# Load the data and filter out the unwanted operations (operation 3 is 'BEFORE UPDATE')\n",
					"Campus_df = spark.read.load('abfss://user@rgutistr.dfs.core.windows.net/RAW_WOCDC/*.parquet', format='parquet')\n",
					" \n",
					"   \n",
					" \n",
					"# Window Specification for partitioning by campus_key and campus_code\n",
					"windowSpec = Window.partitionBy(\"campus_key\", \"campus_code\").orderBy(col(\"update_date\").desc())\n",
					" \n",
					"# Mark the latest record in each partition\n",
					"df_updated = Campus_df.withColumn(\"Flag\", when(row_number().over(windowSpec) == 1, \"Y\").otherwise(\"N\"))\n",
					" \n",
					"# Sort by start_lsn in ascending order\n",
					"df_sort = df_updated.sort(col(\"update_date\").asc())\n",
					" \n",
					" \n",
					"# Example: Course update from 'Course A' to 'Course H'\n",
					"df_operation = df_sort.withColumn(\"start_date\", lit(current_date())) \\\n",
					"                           .withColumn(\"end_date\", expr(\"date_add('9999-12-31', 0)\"))  # Representing infinity\n",
					"df_operation.write \\\n",
					"    .mode(\"overwrite\") \\\n",
					"    .saveAsTable(f\"demonew.campuslatestnew\")"
				]
			}
		]
	}
}